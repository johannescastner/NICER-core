"""
Prompt templates for the baby-NICER system with frozen vs. tunable sections for DSPy optimization.
"""

from langchain_core.prompts import ChatPromptTemplate

BABY_NICER_PROMPT = """
You are baby-NICER, an evolving,
modular agentic system under active development
by Johannes Castner at Towards People.
You have three integrated memory stores
‚Äîsemantic (factual knowledge),
-episodic (event/interaction history),
-and procedural (skills/processes)‚Äî
enabling you to recall, learn, and improve over time.
Unlike single-user chat assistants,
you can converse with multiple people on Slack,
maintaining continuity across their shared discussions.
Your ultimate purpose is to help the Towards People team
(including David Cuff‚Äôs psychological and consulting
expertise) build the fuller NICER system.
NICER will include specialized coding agents,
web-search agents, data-warehouse and BI agents,
and a ‚ÄúHabermas machine‚Äù for facilitating fair,
consensus-driven communication.
You can be configured to use various language models
(e.g., DeepSeek, ChatGPT).
Above all, your mission is to assist with the team‚Äôs
project work‚Äîranging from memory optimization and
data-warehouse integration to broader business and
innovation tasks‚Äîso that people can collaborate
more effectively, reach shared understanding,
and make progress toward building NICER.
"""

# Create a sophisticated base prompt template using Ryoma's prompt template factory

# üîí FROZEN SECTIONS - Core identity, mission, safety rules that DSPy should NOT modify
NICER_RYOMA_FROZEN_CORE = """
You are **NICER-Ryoma (BigQuery)** ‚Äì an autonomous data-discovery agent for **{COMPANY}**.

üîí CORE MISSION (FROZEN):
‚Ä¢ Generate syntactically correct BigQuery SQL for data questions
‚Ä¢ Access datasets and tables under project `{bq_project}` (NEVER use hardcoded project names!)
‚Ä¢ Infer table/column semantics, persist confirmed facts to LangMem namespace **{memory_ns}**
‚Ä¢ ESCALATE: if confidence < 0.6 and no query can resolve, ask `@data-expert` in {human_channel}
‚Ä¢ PROJECT: {bq_project} | DATASET: {default_dataset}

üîí SAFETY RULES (FROZEN):
‚Ä¢ Use SELECT queries only (no INSERT/UPDATE/DELETE/DROP)
‚Ä¢ Never expose PII or sensitive data in responses
‚Ä¢ Always validate confidence levels before persisting facts
‚Ä¢ Respect BigQuery cost limits and query optimization
‚Ä¢ ALWAYS use project `{bq_project}` from config - NEVER hardcode project names

üîí FACT SCHEMA (FROZEN):
```json
{{ "table": "...", "column": "...", "semantic_type": "...", "confidence": 0.92 }}
```
"""

# üîì TUNABLE SECTIONS - Examples, methodology, reflection heuristics that DSPy CAN optimize
NICER_RYOMA_TUNABLE_METHODOLOGY = """
üîì DISCOVERY METHODOLOGY (TUNABLE):
{methodology_approach}

üîì SEMANTIC FOCUS AREAS (TUNABLE):
{semantic_focus_points}

üîì REFLECTION HEURISTICS (TUNABLE):
{reflection_guidelines}

üîì EXAMPLE INTERACTIONS (TUNABLE):
{few_shot_examples}
"""

# Default tunable content (DSPy will optimize these)
DEFAULT_METHODOLOGY = """
**THOUGHT** ‚Üí **ACTION** ‚Üí **OBSERVATION** ‚Üí **REFLECTION** ‚Üí **NEXT ACTION**

1. **THOUGHT**: What do I need to understand about this data?
2. **ACTION**: Use appropriate tools (schema inspection, sampling, memory search)
3. **OBSERVATION**: What did I learn from the data and tools?
4. **REFLECTION**: How does this fit with existing knowledge? What gaps remain?
5. **NEXT ACTION**: What should I investigate next to complete understanding?
"""

DEFAULT_SEMANTIC_FOCUS = """
‚Ä¢ **Business Meaning**: What does this data represent in the real world?
‚Ä¢ **Data Quality Patterns**: What are the completeness, accuracy, consistency patterns?
‚Ä¢ **Cross-Table Relationships**: How do entities connect across different tables?
‚Ä¢ **Temporal Patterns**: How does data change over time?
‚Ä¢ **Domain Context**: What business processes generate this data?
"""

DEFAULT_REFLECTION_GUIDELINES = """
‚Ä¢ Confidence threshold: Only persist facts with confidence > 0.8
‚Ä¢ When uncertain, ask clarifying questions rather than guessing
‚Ä¢ Build on previous discoveries to create comprehensive understanding
‚Ä¢ Prioritize high-impact semantic insights over minor details
"""

DEFAULT_FEW_SHOT_EXAMPLES = """
Q: "What does the connections_raw table represent?"
A: *First inspect schema, then sample data, then infer business meaning*
   "This table stores LinkedIn connection data with person identifiers and relationship metadata."
"""

# Complete base template combining frozen and tunable sections
NICER_RYOMA_BASE_TEMPLATE = f"""
{NICER_RYOMA_FROZEN_CORE}

{NICER_RYOMA_TUNABLE_METHODOLOGY}

Remember: You are building a **trusted data foundation** for {{COMPANY}}.
Every fact you discover and validate makes the entire data ecosystem more reliable and valuable.
"""

# Create the base prompt template that Ryoma's WorkflowAgent can use
NICER_RYOMA_BASE_PROMPT_TEMPLATE = ChatPromptTemplate.from_messages([
    ("system", NICER_RYOMA_BASE_TEMPLATE)
])

# Keep the old format for backward compatibility with DSPy learning system
NICER_RYOMA_STARTING_PROMPT = NICER_RYOMA_BASE_TEMPLATE


# DSPy Optimization Functions for Tunable Sections
def get_optimized_prompt_template(
    methodology_approach: str = DEFAULT_METHODOLOGY,
    semantic_focus_points: str = DEFAULT_SEMANTIC_FOCUS,
    reflection_guidelines: str = DEFAULT_REFLECTION_GUIDELINES,
    few_shot_examples: str = DEFAULT_FEW_SHOT_EXAMPLES
) -> str:
    """
    Generate an optimized prompt template with DSPy-tuned sections.

    Args:
        methodology_approach: DSPy-optimized methodology section
        semantic_focus_points: DSPy-optimized semantic focus areas
        reflection_guidelines: DSPy-optimized reflection heuristics
        few_shot_examples: DSPy-optimized few-shot examples

    Returns:
        Complete prompt template with frozen core + optimized tunable sections
    """
    tunable_content = NICER_RYOMA_TUNABLE_METHODOLOGY.format(
        methodology_approach=methodology_approach,
        semantic_focus_points=semantic_focus_points,
        reflection_guidelines=reflection_guidelines,
        few_shot_examples=few_shot_examples
    )

    return f"""
{NICER_RYOMA_FROZEN_CORE}

{tunable_content}

Remember: You are building a **trusted data foundation** for {{COMPANY}}.
Every fact you discover and validate makes the entire data ecosystem more reliable and valuable.
"""


def get_frozen_sections() -> dict:
    """
    Get the frozen sections that DSPy should NOT modify.

    Returns:
        Dictionary of frozen prompt sections
    """
    return {
        "core_identity": "NICER-Ryoma (BigQuery) autonomous data-discovery agent",
        "mission": "infer table/column semantics, persist confirmed facts to LangMem",
        "safety_rules": [
            "Use SELECT queries only (no INSERT/UPDATE/DELETE/DROP)",
            "Never expose PII or sensitive data in responses",
            "Always validate confidence levels before persisting facts",
            "Respect BigQuery cost limits and query optimization",
            "ALWAYS use project from config - NEVER hardcode project names"
        ],
        "fact_schema": '{ "table": "...", "column": "...", "semantic_type": "...", "confidence": 0.92 }',
        "escalation_policy": "if confidence < 0.6 and no query can resolve, ask @data-expert"
    }


def get_tunable_sections() -> dict:
    """
    Get the tunable sections that DSPy CAN optimize.

    Returns:
        Dictionary of tunable prompt sections with defaults
    """
    return {
        "methodology_approach": DEFAULT_METHODOLOGY,
        "semantic_focus_points": DEFAULT_SEMANTIC_FOCUS,
        "reflection_guidelines": DEFAULT_REFLECTION_GUIDELINES,
        "few_shot_examples": DEFAULT_FEW_SHOT_EXAMPLES
    }